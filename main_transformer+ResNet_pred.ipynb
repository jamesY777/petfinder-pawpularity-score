{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "# from transformers import ViTFeatureExtractor, ViTModel, ViTConfig, AutoConfig\n",
    "\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to redefine the local class to load the weights\n",
    "class model_final(nn.Module):\n",
    "    def __init__(self, model_trans_top, trans_layer_norm, model_Res, dp_rate = 0.3):\n",
    "        super().__init__()\n",
    "        # All the trans model layers\n",
    "        self.model_trans_top = model_trans_top\n",
    "        self.trans_layer_norm = trans_layer_norm\n",
    "        self.trans_flatten = nn.Flatten()\n",
    "        self.trans_linear = nn.Linear(150528, 2048)\n",
    "\n",
    "        # All the ResNet model\n",
    "        self.model_Res = model_Res\n",
    "\n",
    "        # Merge the result and pass the\n",
    "        self.dropout = nn.Dropout(dp_rate)\n",
    "        self.linear1 = nn.Linear(4096, 500)\n",
    "        self.linear2 = nn.Linear(500,1)\n",
    "\n",
    "    def forward(self, trans_b, res_b):\n",
    "        # Get intermediate outputs using hidden layer\n",
    "        result_trans = self.model_trans_top(trans_b)\n",
    "        patch_state = result_trans.last_hidden_state[:,1:,:] # Remove the classification token and get the last hidden state of all patchs\n",
    "        result_trans = self.trans_layer_norm(patch_state)\n",
    "        result_trans = self.trans_flatten(patch_state)\n",
    "        result_trans = self.dropout(result_trans)\n",
    "        result_trans = self.trans_linear(result_trans)\n",
    "\n",
    "        result_res = self.model_Res(res_b)\n",
    "        # result_res = result_res.squeeze() # Batch size cannot be 1\n",
    "        result_res = torch.reshape(result_res, (result_res.shape[0], result_res.shape[1]))\n",
    "\n",
    "        result_merge = torch.cat((result_trans, result_res),1)\n",
    "        result_merge = self.dropout(result_merge)\n",
    "        result_merge = self.linear1(result_merge)\n",
    "        result_merge = self.dropout(result_merge)\n",
    "        result_merge = self.linear2(result_merge)\n",
    "\n",
    "        return result_merge\n",
    "\n",
    "device = torch.device('cpu')\n",
    "model = torch.load('model_1228', map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"test.csv\")\n",
    "df[\"file_path\"] = df[\"Id\"].apply(lambda Id: \"test/\" + Id + \".jpg\") # Create image path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class petDataset_pred(Dataset):\n",
    "    def __init__(self, dataframe, trans_transform=None, res_transform=None):\n",
    "        self.images = dataframe[\"file_path\"]\n",
    "        self.trans_transform = trans_transform\n",
    "        self.res_transform = res_transform\n",
    "\n",
    "    def __len__ (self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        image = Image.open(img_path)\n",
    "\n",
    "        image_trans = self.trans_transform(image)\n",
    "\n",
    "        image_res = self.res_transform(image)\n",
    "        return image_trans, image_res\n",
    "\n",
    "trans_transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "])\n",
    "res_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "\n",
    "test_ds = petDataset_pred(df, trans_transform=trans_transform, res_transform=res_transform)\n",
    "test_dl = DataLoader(test_ds, batch_size=2, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = np.array([])\n",
    "\n",
    "for x_trans, x_res in test_dl:\n",
    "    result = model(x_trans, x_res)\n",
    "    output = np.append(output, result.cpu().detach().numpy())\n",
    "\n",
    "df_submission = pd.read_csv('sample_submission.csv')\n",
    "df_submission[\"Pawpularity\"] = output\n",
    "df_submission.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0b474fbca583db9755915e6860e2fde94bc14d2074e9b53ec47630e7810fa628"
  },
  "kernelspec": {
   "display_name": "Python 3.8.7 64-bit ('petfinder': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
