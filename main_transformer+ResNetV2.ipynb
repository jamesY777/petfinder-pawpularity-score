{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from transformers import ViTFeatureExtractor, ViTModel, ViTConfig, AutoConfig\n",
    "\n",
    "from PIL import Image\n",
    "from torchsummary import summary\n",
    "import GPUtil\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Training data\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "df[\"file_path\"] = df[\"Id\"].apply(lambda Id: \"train/\" + Id + \".jpg\") # Create image path\n",
    "df[\"Pawpularity\"] = df[\"Pawpularity\"].values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to add data/model in to GPU (cuda)\n",
    "def get_default_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "def to_device(data, device):\n",
    "    # if data is list or tuple, move each of them to device\n",
    "    if isinstance(data, (list, tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    def __init__(self, dl, device) -> None:\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "\n",
    "    def __iter__(self):\n",
    "        for b in self.dl:\n",
    "            # yield only execuate when the function is called\n",
    "            yield to_device(b, self. device)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training dataset\n",
    "class petDataset(Dataset):\n",
    "    def __init__(self, dataframe, trans_transform=None, res_transform=None):\n",
    "        self.labels = dataframe[\"Pawpularity\"]\n",
    "        self.images = dataframe[\"file_path\"]\n",
    "        self.trans_transform = trans_transform\n",
    "        self.res_transform = res_transform\n",
    "\n",
    "    def __len__ (self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        image = Image.open(img_path)\n",
    "\n",
    "        image_trans = self.trans_transform(np.array(image), return_tensors='pt')\n",
    "        image_trans = image_trans['pixel_values'].squeeze()\n",
    "\n",
    "        image_res = self.res_transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        return image_trans, image_res, label\n",
    "\n",
    "trans_transform = ViTFeatureExtractor.from_pretrained('google/vit-large-patch16-224')\n",
    "res_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "\n",
    "train_ds = petDataset(df, trans_transform=trans_transform, res_transform=res_transform)\n",
    "train_dl = DataLoader(train_ds, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\yscaa/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "# Modify the model - ResNet\n",
    "model_Res = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)\n",
    "\n",
    "# Remove the last layer of the model Res\n",
    "layers_Res = list(model_Res.children())\n",
    "model_Res = nn.Sequential(*layers_Res[:-1])\n",
    "\n",
    "# Set the top layers to be not trainable\n",
    "count = 0\n",
    "for child in model_Res.children():\n",
    "    count += 1\n",
    "    if count < 8:\n",
    "        for param in child.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the model - ViT model\n",
    "model_trans = ViTModel.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "count = 0\n",
    "for child in model_trans.children():\n",
    "    count += 1\n",
    "    if count < 4:\n",
    "        for param in child.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "layers_trans = list(model_trans.children()) # Get all the layers from the Transformer model\n",
    "model_trans_top = nn.Sequential(*layers_trans[:-2]) # Remove the normalization layer and pooler layer\n",
    "trans_layer_norm = list(model_trans.children())[2] # Get the normalization layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the two models\n",
    "class model_final(nn.Module):\n",
    "    def __init__(self, model_trans_top, trans_layer_norm, model_Res, dp_rate = 0.3):\n",
    "        super().__init__()\n",
    "        # All the trans model layers\n",
    "        self.model_trans_top = model_trans_top\n",
    "        self.trans_layer_norm = trans_layer_norm\n",
    "        self.trans_flatten = nn.Flatten()\n",
    "        self.trans_linear = nn.Linear(150528, 2048)\n",
    "\n",
    "        # All the ResNet model\n",
    "        self.model_Res = model_Res\n",
    "\n",
    "        # Merge the result and pass the\n",
    "        self.dropout = nn.Dropout(dp_rate)\n",
    "        self.linear1 = nn.Linear(4096, 500)\n",
    "        self.linear2 = nn.Linear(500,1)\n",
    "\n",
    "    def forward(self, trans_b, res_b):\n",
    "        # Get intermediate outputs using hidden layer\n",
    "        result_trans = self.model_trans_top(trans_b)\n",
    "        patch_state = result_trans.last_hidden_state[:,1:,:] # Remove the classification token and get the last hidden state of all patchs\n",
    "        result_trans = self.trans_layer_norm(patch_state)\n",
    "        result_trans = self.trans_flatten(patch_state)\n",
    "        result_trans = self.dropout(result_trans)\n",
    "        result_trans = self.trans_linear(result_trans)\n",
    "\n",
    "        result_res = self.model_Res(res_b)\n",
    "        # result_res = result_res.squeeze() # Batch size cannot be 1\n",
    "        result_res = torch.reshape(result_res, (result_res.shape[0], result_res.shape[1]))\n",
    "\n",
    "        result_merge = torch.cat((result_trans, result_res),1)\n",
    "        result_merge = self.dropout(result_merge)\n",
    "        result_merge = self.linear1(result_merge)\n",
    "        result_merge = self.dropout(result_merge)\n",
    "        result_merge = self.linear2(result_merge)\n",
    "\n",
    "        return result_merge\n",
    "\n",
    "model = model_final(model_trans_top, trans_layer_norm, model_Res, dp_rate = 0.3)\n",
    "# model.load_state_dict(torch.load('model_weights_1228'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add data and model to GPU\n",
    "device = get_default_device()\n",
    "train_dl = DeviceDataLoader(train_dl, device)\n",
    "model = to_device(model, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer and learning_rate scheduler\n",
    "params = [param for param in list(model.parameters()) if param.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=1e-7, momentum=0.2)\n",
    "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, \n",
    "    mode='min', \n",
    "    factor=0.1, \n",
    "    patience=2, \n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit function doing grad steps\n",
    "def fit(epochs, model, train_dl):   \n",
    "    opt = optimizer\n",
    "    sched = lr_scheduler\n",
    "    loss_func = nn.MSELoss()\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        batch_num = 1\n",
    "        for x_trans, x_res, yb in train_dl:\n",
    "            # Pass the opt so that funciton will get trained\n",
    "            total_loss = 0\n",
    "            preds = model(x_trans, x_res)\n",
    "            loss = loss_func(preds.squeeze(), yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "            print('\\r', f'batch #{batch_num}: {loss}', end='')\n",
    "            batch_num += 1\n",
    "            total_loss += loss.item()\n",
    "        sched.step(total_loss)\n",
    "        print('\\n', f'Epoch: ({epoch+1}/{epochs}) Loss = {total_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model and save weights\n",
    "fit(10, model, train_dl)\n",
    "torch.save(model.state_dict(), \"model_weights_1228\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and build the test dataset\n",
    "df_prd = pd.read_csv(\"test.csv\")\n",
    "df_prd[\"file_path\"] = df_prd[\"Id\"].apply(lambda Id: \"test/\" + Id + \".jpg\") # Create image path\n",
    "class petDataset_prd(Dataset):\n",
    "    def __init__(self, dataframe, trans_transform=None, res_transform=None):\n",
    "        self.images = dataframe[\"file_path\"]\n",
    "        self.trans_transform = trans_transform\n",
    "        self.res_transform = res_transform\n",
    "\n",
    "    def __len__ (self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        image = Image.open(img_path)\n",
    "\n",
    "        image_trans = self.trans_transform(np.array(image), return_tensors='pt')\n",
    "        image_trans = image_trans['pixel_values'].squeeze()\n",
    "\n",
    "        image_res = self.res_transform(image)\n",
    "\n",
    "        return image_trans, image_res\n",
    "\n",
    "trans_transform = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "res_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "test_ds = petDataset_prd(df_prd, trans_transform=trans_transform, res_transform=res_transform)\n",
    "test_dl = DataLoader(test_ds, batch_size=8, shuffle=False)\n",
    "test_dl = DeviceDataLoader(test_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model_trans, model_Res, model_linear, test_dl):\n",
    "    for image_trans, image_res in test_dl:\n",
    "        trans_output = model_trans(image_trans)\n",
    "        cls_tokens = trans_output.pooler_output\n",
    "        res_output = model_Res(image_res)\n",
    "        output = torch.cat((cls_tokens,res_output),1)\n",
    "        preds = model_linear(output)      \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = predict(model_trans, model_Res, model_linear, test_dl)\n",
    "df_prd[\"Pawpularity\"] = result.cpu().detach().numpy()\n",
    "df_prd[[\"Id\", \"Pawpularity\"]].to_csv(\"test1.csv\", index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0b474fbca583db9755915e6860e2fde94bc14d2074e9b53ec47630e7810fa628"
  },
  "kernelspec": {
   "display_name": "Python 3.8.7 64-bit ('petfinder': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
